# option-density-viz

_Risk-neutral probability density visualization from options on **crypto (BTC/ETH)** and **equities (AAPL/SPY)** using **OKX (public)** and **yfinance**._

![Python](https://img.shields.io/badge/python-3.10+-blue.svg)
![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)
![Build Status](https://img.shields.io/badge/build-passing-brightgreen.svg)

---

## ğŸ“Œ Overview

`option-density-viz` is a research and visualization tool that extracts **risk-neutral probability densities (RNDs)** from options market data.  
It normalizes live **BTC/ETH** options from the **OKX public API** and **equity** options via **yfinance**, fits (planned) **implied volatility smiles** using an arbitrage-aware **SVI** workflow, then applies the **Breedenâ€“Litzenberger relation** and (planned) **COS method** to compute and plot the probability density of future prices.

This project is designed to help **quantitative researchers, students, and traders** understand how option markets are pricing future outcomes and uncertainty.

> Note: The data layer (OKX + yfinance), caching, rate-limiting/retries, historical I/O, and risk-free rates are implemented. SVI fitting, no-arb checks, and COS/BL pipelines are an active roadmap.

---

## âœ¨ Features

- ğŸ”— **Live API ingestion** â€” pull BTC/ETH option chains from **OKX (public endpoints, no keys required)**, plus equity chains from **yfinance**.
- ğŸ§± **Unified schema** â€” a single `OptionQuote`/`OptionChain` model for crypto and equities.
- ğŸ’¾ **Reproducibility** â€” save/load chains to **CSV/Parquet**; build offline datasets for experiments.
- ğŸš¦ **Polite data fetching** â€” **TTL cache** (in-mem + SQLite), **async** calls, **rate-limit** gate + **exponential backoff** retries.
- ğŸ“ˆ **Implied volatility surface fitting (SVI)** â€” scaffolding in place; no-arbitrage checks on the roadmap.
- ğŸ§® **Risk-neutral density extraction** â€” via **Breedenâ€“Litzenberger** (second derivative) and **COS** (Fourier) methods (roadmap).
- ğŸ¨ **Visualization** â€” Matplotlib plots for smiles/densities; Streamlit dashboard planned.
- ğŸ“Š **Analytics add-ons** â€” implied mean, skewness, and kurtosis of the distribution (roadmap).

---

## ğŸ— Project Structure

```
option-density-viz/
â”‚â”€â”€ src/
â”‚   â”œâ”€â”€ data/               # Backends & plumbing (OKX, yfinance, caching, I/O)
â”‚   â”‚   â”œâ”€â”€ base.py         # OptionQuote, OptionChain, OptionFetcher protocol
â”‚   â”‚   â”œâ”€â”€ registry.py     # get_fetcher("equity"|"crypto")
â”‚   â”‚   â”œâ”€â”€ yf_fetcher.py   # Equity via yfinance (async via to_thread)
â”‚   â”‚   â”œâ”€â”€ okx_fetcher.py  # Crypto via OKX (public endpoints)
â”‚   â”‚   â”œâ”€â”€ cache.py        # KVCache (in-mem + SQLite TTL)
â”‚   â”‚   â”œâ”€â”€ historical_loader.py  # CSV/Parquet save/load
â”‚   â”‚   â”œâ”€â”€ risk_free.py    # SOFR CSV loader + constant fallback
â”‚   â”‚   â””â”€â”€ rate_limit.py   # AsyncRateLimiter + retry_with_backoff
â”‚   â”œâ”€â”€ vol/                # (Roadmap) SVI fitting, no-arb checks, surfaces
â”‚   â”œâ”€â”€ density/            # (Roadmap) BL finite diffs, COS method
â”‚   â””â”€â”€ viz/                # Plots and (planned) Streamlit dashboard
â”‚â”€â”€ notebooks/
â”‚   â””â”€â”€ data_test.ipynb     # End-to-end data validation & demos
â”‚â”€â”€ docs/                   # Images, examples, extended documentation
â”‚â”€â”€ requirements.txt        # Python dependencies
â”‚â”€â”€ README.md               # Project overview
â”‚â”€â”€ LICENSE                 # License file
```

---

## âš¡ Installation

Clone the repository and install dependencies:

```bash
git clone https://github.com/yourusername/option-density-viz.git
cd option-density-viz
pip install -r requirements.txt
```

**Dependencies (core):**

- Python 3.10+
- `numpy`, `scipy`, `pandas`
- `matplotlib`
- **Backends:** `httpx`, `yfinance`
- **Optional:** `pyarrow` or `fastparquet` for Parquet, `python-dotenv` for local env loading

> We no longer use Deribit or `websockets`. Crypto data comes from **OKX public REST**.

---

## ğŸš€ Usage

Run the **validation notebook** to fetch data, inspect a chain, and export CSV/Parquet:

```text
notebooks/data_test.ipynb
```

Or try a minimal script:

```python
# examples/quickstart.py
import asyncio
from data.registry import get_fetcher

async def main():
    # Equity example (AAPL)
    yf = get_fetcher("equity")
    exps = await yf.list_expiries("AAPL")
    chain_eq = await yf.fetch_chain("AAPL", exps[0])
    print("AAPL spot:", chain_eq.spot, "| quotes:", len(chain_eq.quotes))

    # Crypto example (BTC via OKX public)
    okx = get_fetcher("crypto")
    exps_c = await okx.list_expiries("BTC")
    chain_cr = await okx.fetch_chain("BTC", exps_c[0])
    print("BTC spot:", chain_cr.spot, "| quotes:", len(chain_cr.quotes))

if __name__ == "__main__":
    asyncio.run(main())
```

<!-- Example output:

![Demo Plot](docs/example_density.png) -->

---

## ğŸ“Š Results

This section highlights example artifacts and the **metrics** we track to sanityâ€‘check calibrations and densities. Commit a small set of figures to `docs/` so reviewers can skim results without running anything.

### Artifacts (examples)

- `docs/example_smile_aapl.png` â€” AAPL IV smile at a recent expiry
- `docs/example_density_btc.png` â€” BTC riskâ€‘neutral PDF at a recent expiry
- `docs/example_cdf_btc.png` â€” BTC CDF with key quantiles

> Tip: Export plots from the validation notebook and drop the files into `docs/` with short, dated filenames.

### Metrics we report

We summarize each snapshot (per expiry) with:

| Metric | Meaning | Target / Check |
|---|---|---|
| Quotes used | Cleaned quotes after filters | Higher is better |
| VW-RMSE (total variance) | Vegaâ€‘weighted fit error in **total variance** | â†“ vs. ATMâ€‘only baseline |
| Butterfly violations | Fraction of strikes with negative second derivative | < 1% |
| Calendar violations | Any decrease of total variance with maturity | 0 |
| âˆ«pdf âˆ’ 1 | Density normalization error | â‰¤ 1eâ€‘2 |
| RN mean âˆ’ Forward (bps) | Riskâ€‘neutral mean vs forward | â‰ˆ 0 |
| Negative pdf rate | Share of grid with pdf < 0 | â‰ˆ 0 |
| Runtime (s) | Seconds per expiry | Informational |

> Until the modeling modules land, focus results on **data completeness**, **consistency** (PCP/forward checks), and **reproducibility** (CSV/Parquet roundâ€‘trips).

### Reproduce these results

1. Run `notebooks/OptionViz_Data_Tests.ipynb` for **AAPL** and **BTC**.  
2. Export figures to `docs/` (e.g., `example_smile_aapl.png`, `example_density_btc.png`).  
3. (When modeling modules are added) run the â€œReportâ€ cell to print/save a metrics table (CSV/JSON) to `docs/results/`.

## ğŸ“š Theory Background

- **Breedenâ€“Litzenberger (1978)**: Risk-neutral density can be obtained as the **second derivative** of option prices w.r.t. strike.
- **SVI (Stochastic Volatility Inspired)**: Robust parametrization of implied volatility smiles that enforces arbitrage-aware conditions.
- **COS method**: Fourier expansion method that recovers probability densities from characteristic functions, offering numerical stability.

---

## ğŸ§  Theory Deep Dive

This project sits at the intersection of **derivatives pricing** and **numerical analysis**. Below are the core concepts and how we use them.

### 1) Riskâ€‘neutral measure, forwards, and logâ€‘moneyness

- Under the **riskâ€‘neutral (Q) measure**, discounted asset prices are martingales. Pricing expectations are taken under Q with the riskâ€‘free discount.
- **Putâ€“Call Parity (PCP)** for European options (no divs): `C âˆ’ P = S âˆ’ K e^{âˆ’rT}`. With dividends/carry you use `S_0 e^{âˆ’qT}` or the **forward** `F = S_0 e^{(râˆ’q)T}`.
- We prefer to work in **logâ€‘moneyness**: `k = ln(K / F)`. This centers smiles across assets and maturities and is the natural coordinate for SVI.

### 2) From implied volatility to total variance

- Market quotes give implied volatilities `Ïƒ_imp(K, T)` (or prices). We convert to **total variance** `w(k, T) = Ïƒ_imp^2(T) Â· T`.
- SVI and many noâ€‘arbitrage conditions are easier to express in terms of `w` (linear in time and convex in strike).

### 3) SVI smile (per expiry) and calibration

- **SVI (Stochastic Volatility Inspired)** parameterizes total variance for a fixed `T`:

  ```
  w(k) = a + b { Ï (k âˆ’ m) + sqrt( (k âˆ’ m)^2 + Ïƒ^2 ) }
  ```

  Parameters: `a` (level), `b` (slope), `Ï` (skew, |Ï|<1), `m` (shift), `Ïƒ` (wing curvature, >0).
- **Why SVI?** It fits empirical smiles well and admits known **sufficient conditions** for (approximate) noâ€‘arbitrage.
- **Calibration tips used/planned**:
  - **Seeds** from coarse grid / heuristics (ATM slope/curvature).
  - **Vegaâ€‘weighted loss** in **total variance** (not IV) to emphasize informative strikes.
  - **Bounds/regularization** on `(a,b,Ï,m,Ïƒ)` to avoid pathological wings.
  - (Across maturities) smooth parameters over `T` and check calendar monotonicity of `w(Â·,T)`.

### 4) Noâ€‘arbitrage checks (sanity layer)

- **Butterfly (static) arbitrage:** Calls must be **convex in K** (`âˆ‚Â²C/âˆ‚KÂ² â‰¥ 0`). We screen the fitted smile or the price curve for negativity.
- **Calendar arbitrage:** Total variance should be **nonâ€‘decreasing in T** for fixed `k`. We spotâ€‘check adjacent maturities.
- **Data hygiene:** Filter **crossed** (`bid>ask`) / **wide** spreads and stale quotes; compute robust mids before fitting.

### 5) Breedenâ€“Litzenberger (BL) density (modelâ€‘free)

- BL states the **riskâ€‘neutral PDF** is the **second derivative** of the call price with respect to strike (under mild conditions):

  ```
  f_Q(K,T) = âˆ‚Â²C(K,T)/âˆ‚KÂ² Â· e^{rT}
  ```

- Numerically fragile â†’ we stabilize by:
  - Smoothing the **call price curve** in `K` (e.g., monotone splines / regularized fits).
  - Using **central or higherâ€‘order finite differences** with **adaptive spacing**.
  - Enforcing **boundary behavior** (wing extrapolation consistent with forwards).
- Diagnostics: `f_Q â‰¥ 0`, `âˆ« f_Q dK â‰ˆ 1`, RN mean â‰ˆ forward.

### 6) COS method (spectral, modelâ€‘driven)

- **COS** recovers densities/prices from a **characteristic function** via a truncated cosine series on `[a,b]`:

  ```
  C(K) â‰ˆ e^{âˆ’rT} \sum_{n=0}^{Nâˆ’1} Re( Ï•( u_n ) Â· F_n(K) )
  ```

  where `Ï•` is the CF of logâ€‘price, `u_n = nÏ€/(bâˆ’a)`, and `F_n` are known coefficients.
- Key practical choices:
  - **Truncation bounds** `[a,b]` from **cumulants** (match mean/variance/skew/kurtosis).
  - **Series length** `N` from an error budget (trade speed vs accuracy).
- COS is extremely fast and stable once `Ï•` is known; we use it to crossâ€‘check BL.

### 7) Diagnostics & consistency checks

- **Normalization**: `| âˆ« f_Q âˆ’ 1 | â‰¤ 1eâˆ’2`.
- **Forward consistency**: RN mean vs forward within a few **bps**.
- **Moment checks**: Compare variance/skew/kurtosis from the density to those implied by the smile.
- **Priceâ€‘fromâ€‘density**: Reâ€‘integrate the density to recover call prices and measure error.

> In practice, a robust pipeline alternates between **modeling** (SVI/COS) and **modelâ€‘free** (BL) views, using diagnostics to decide when to trust which.

---

## ğŸ›  Roadmap

- [ ] SVI calibration with regularization + no-arbitrage checks
- [ ] BL derivative (high-order finite differences) and COS pipeline
- [ ] Streamlit dashboard (interactive smiles/densities)
- [ ] Calibration comparisons (SVI vs SABR)
- [ ] Additional asset classes (index options like SPX/QQQ)

---

## ğŸ¤ Contributing

Contributions are welcome!

1. Fork the repo  
2. Create a feature branch (`git checkout -b feature/my-feature`)  
3. Commit changes (`git commit -m 'Add feature'`)  
4. Push branch (`git push origin feature/my-feature`)  
5. Open a Pull Request

---

## ğŸ“œ License

MIT License Â© 2025 `option-density-viz` contributors.  
See [LICENSE](LICENSE) for details.

---

## ğŸ‘¥ Authors

- [Drew Verzino](https://github.com/drewverzino)
- [Rahul Rajesh](https://github.com/RajeshGang)
- [Tinashe Dwemza](https://github.com/tinashe13)

---

## ğŸ™Œ Acknowledgments

- **OKX** for public crypto options data  
- **yfinance** for convenient equity options data  
- Jim Gatheral for the **SVI volatility smile framework**  
- Breeden & Litzenberger (1978) for the foundational density extraction method
